{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T07:25:33.956128Z",
     "iopub.status.busy": "2022-04-02T07:25:33.955781Z",
     "iopub.status.idle": "2022-04-02T07:25:46.684787Z",
     "shell.execute_reply": "2022-04-02T07:25:46.683983Z",
     "shell.execute_reply.started": "2022-04-02T07:25:33.956035Z"
    },
    "id": "4oW6Xqe7NLUJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install --quiet torch torchvision matplotlib pytorch-lightning\n",
    "! pip install --quiet ipywidgets IProgress\n",
    "! jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T07:25:46.686604Z",
     "iopub.status.busy": "2022-04-02T07:25:46.686336Z",
     "iopub.status.idle": "2022-04-02T07:25:49.708047Z",
     "shell.execute_reply": "2022-04-02T07:25:49.707366Z",
     "shell.execute_reply.started": "2022-04-02T07:25:46.686578Z"
    },
    "id": "5Vx6AeRCNRfW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch 1.11.0a0+17540c5\n",
      "Is the GPU available? True\n",
      "Device cuda\n",
      "GPUs avaiable:  1\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from IPython.display import set_matplotlib_formats\n",
    "from matplotlib.colors import to_rgba\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.nn.modules.conv import Conv2d, ConvTranspose2d\n",
    "from torch.nn.modules.activation import ReLU, Sigmoid\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "import torchvision\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Using torch\", torch.__version__)\n",
    "torch.manual_seed(42)\n",
    "gpu_avail = torch.cuda.is_available()\n",
    "print(f\"Is the GPU available? {gpu_avail}\")\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device\", device)\n",
    "available_gpus = [torch.cuda.device(i) for i in range(torch.cuda.device_count())]\n",
    "NUM_GPUS = len(available_gpus)\n",
    "print(\"GPUs avaiable: \", NUM_GPUS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T07:54:19.996020Z",
     "iopub.status.busy": "2022-04-02T07:54:19.995039Z",
     "iopub.status.idle": "2022-04-02T07:54:22.267552Z",
     "shell.execute_reply": "2022-04-02T07:54:22.266709Z",
     "shell.execute_reply.started": "2022-04-02T07:54:19.995980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "transform = transforms.Compose([\n",
    "      transforms.ToTensor(),                 \n",
    "])\n",
    "lfw_data = datasets.LFWPeople(root=\"./train_data\", split=\"train\", download=True, transform=transform)\n",
    "lfw_data_val = datasets.LFWPeople(root=\"./val_data\", split=\"test\", download=True, transform=transform)\n",
    "data_loader = DataLoader(dataset=lfw_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "data_loader_val = DataLoader(dataset=lfw_data_val, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T07:28:07.893392Z",
     "iopub.status.busy": "2022-04-02T07:28:07.893139Z",
     "iopub.status.idle": "2022-04-02T07:28:07.912325Z",
     "shell.execute_reply": "2022-04-02T07:28:07.911460Z",
     "shell.execute_reply.started": "2022-04-02T07:28:07.893365Z"
    },
    "id": "OHhUCBAtRUZK"
   },
   "outputs": [],
   "source": [
    "class AutoEncoderVGG(pl.LightningModule):\n",
    "    def __init__(self, block=1, include_feature_loss=False):\n",
    "        super().__init__()\n",
    "        self.block = block\n",
    "        self.include_feature_loss = include_feature_loss\n",
    "        self.encoder = self.create_encoder()\n",
    "        self.decoder = self.create_decoder()\n",
    "    \n",
    "    def create_encoder(self):\n",
    "        if self.block == 1:\n",
    "            vgg19 = torchvision.models.vgg19(pretrained=True)\n",
    "            vgg_layers = list(list(vgg19.children())[0].children())[:-33]\n",
    "            vgg = nn.Sequential(*vgg_layers)\n",
    "            for p in vgg.parameters():\n",
    "                p.requires_grad = False\n",
    "            return vgg\n",
    "        elif self.block == 3:\n",
    "            vgg19 = torchvision.models.vgg19(pretrained=True)\n",
    "            vgg_layers = list(list(vgg19.children())[0].children())[:-19]\n",
    "            vgg = nn.Sequential(*vgg_layers)\n",
    "            for p in vgg.parameters():\n",
    "                p.requires_grad = False\n",
    "            return vgg\n",
    "        else:\n",
    "            raise ValueError(\"Please supply an encoding layer of either 1 or 3\")\n",
    "    \n",
    "    def create_decoder(self):\n",
    "        if self.block == 1:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(64, 64, 3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(64, 3, 3, stride=1, padding=1),\n",
    "                nn.Sigmoid())\n",
    "        elif self.block == 3:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(256, 256, 3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(256, 256, 3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(256, 256, 3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(256, 128, 3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(128, 128, 3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(128, 64, 3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(64, 64, 3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(64, 3, 3, stride=1, padding=0),\n",
    "                nn.Sigmoid())\n",
    "        else:\n",
    "            raise ValueError(\"Please supply an encoding layer of either 1 or 3\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Autoencode input batch \n",
    "        img, labels = batch    \n",
    "        recon = self.forward(img)\n",
    "        if self.include_feature_loss:\n",
    "            # Calculate reconstruction loss\n",
    "            reconstruction_loss = F.mse_loss(img, recon)\n",
    "            # Calculate feature loss\n",
    "            feature_loss = F.mse_loss(self.encode(img), self.encode(recon))\n",
    "            # Add L2 Norms\n",
    "            loss = reconstruction_loss + feature_loss\n",
    "        else:\n",
    "            # Calculate reconstruction loss\n",
    "            loss = F.mse_loss(img, recon)\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "        #Lightning trainer handles zero_grad, loss.backwards, and optimizer.step\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Autoencode input batch \n",
    "        img, labels = batch    \n",
    "        recon = self.forward(img)\n",
    "        # Calculate reconstruction loss\n",
    "        loss = F.mse_loss(img, recon)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss\n",
    "                                      \n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T06:57:47.048626Z",
     "iopub.status.busy": "2022-04-02T06:57:47.047934Z",
     "iopub.status.idle": "2022-04-02T07:21:10.051329Z",
     "shell.execute_reply": "2022-04-02T07:21:10.050505Z",
     "shell.execute_reply.started": "2022-04-02T06:57:47.048595Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 38.7 K\n",
      "1 | decoder | Sequential | 38.7 K\n",
      "---------------------------------------\n",
      "38.7 K    Trainable params\n",
      "38.7 K    Non-trainable params\n",
      "77.4 K    Total params\n",
      "0.310     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0185a7be98d8464d9ef0c8c7e3424fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee20956b1c74b8c86db2f69d6c73572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71e1ec74c6244eeeade7e61f743b4609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc1ce69713a48ffa6f7b851d3b98599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e64442769bc44c19a182d4baff7fbb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ebbcec613fb45f1849e5ba625562da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f352dd5cf594d6a92b1376d726b7df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "755ab79d6ea5430a86a76b6a882dc638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c0e1658ee643e08b923b6763b1b900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c4e8862c6c42d2bd1188213ddb9795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c8b6384995410cbe61d12c2f173f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1656f16b1e7b4902a0eef21350a1f4dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoEncoderVGG(block=1)\n",
    "logger = CSVLogger(\"logs\", name=\"vgg_block_1_autoencoder\")\n",
    "checkpoint_callback = ModelCheckpoint(dirpath=\"block_1_checkpoints/\", save_top_k=2, monitor=\"val_loss\")\n",
    "trainer = pl.Trainer(max_epochs=10, accelerator=\"gpu\", devices=NUM_GPUS, callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=2), checkpoint_callback], logger=logger)\n",
    "should_train = True\n",
    "if should_train: trainer.fit(model, train_dataloaders=data_loader, val_dataloaders=data_loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T07:22:14.512328Z",
     "iopub.status.busy": "2022-04-02T07:22:14.511404Z",
     "iopub.status.idle": "2022-04-02T07:22:16.548257Z",
     "shell.execute_reply": "2022-04-02T07:22:16.547464Z",
     "shell.execute_reply.started": "2022-04-02T07:22:14.512260Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lightning automatically checkpoints our model during training\n",
    "# However to save a seperate checkpoint so we can ensure we do not\n",
    "# accidentally override we can save manually\n",
    "should_save = True\n",
    "if should_save: trainer.save_checkpoint(\"block_1_model/model.ckpt\")\n",
    "should_load = True\n",
    "if should_load: model = AutoEncoderVGG.load_from_checkpoint(checkpoint_path=\"block_1_model/model.ckpt\", block=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T07:54:28.735420Z",
     "iopub.status.busy": "2022-04-02T07:54:28.735071Z",
     "iopub.status.idle": "2022-04-02T07:55:45.071556Z",
     "shell.execute_reply": "2022-04-02T07:55:45.070572Z",
     "shell.execute_reply.started": "2022-04-02T07:54:28.735361Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 2.3 M \n",
      "1 | decoder | Sequential | 2.3 M \n",
      "---------------------------------------\n",
      "2.3 M     Trainable params\n",
      "2.3 M     Non-trainable params\n",
      "4.7 M     Total params\n",
      "9.302     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408006be25a74460a140ad469768cdb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32740f3a9acb469f960053b3972d090a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoEncoderVGG(block=3, include_feature_loss=True)\n",
    "logger = CSVLogger(\"logs\", name=\"vgg_block_3_autoencoder\")\n",
    "checkpoint_callback = ModelCheckpoint(dirpath=\"block_3_checkpoints/\", save_top_k=2, monitor=\"val_loss\")\n",
    "trainer = pl.Trainer(max_epochs=10, accelerator=\"gpu\", devices=NUM_GPUS, callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=2), checkpoint_callback], logger=logger, precision=16)\n",
    "should_train = True\n",
    "if should_train: trainer.fit(model, train_dataloaders=data_loader, val_dataloaders=data_loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T07:53:06.219289Z",
     "iopub.status.busy": "2022-04-02T07:53:06.219000Z",
     "iopub.status.idle": "2022-04-02T07:53:08.558831Z",
     "shell.execute_reply": "2022-04-02T07:53:08.557816Z",
     "shell.execute_reply.started": "2022-04-02T07:53:06.219245Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lightning automatically checkpoints our model during training\n",
    "# However to save a seperate checkpoint so we can ensure we do not\n",
    "# accidentally override we can save manually\n",
    "should_save = True\n",
    "if should_save: trainer.save_checkpoint(\"block_3_model/model.ckpt\")\n",
    "should_load = True\n",
    "if should_load: model = AutoEncoderVGG.load_from_checkpoint(checkpoint_path=\"block_3_model/model.ckpt\", block=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T04:10:37.535350Z",
     "iopub.status.busy": "2022-04-02T04:10:37.534746Z",
     "iopub.status.idle": "2022-04-02T04:10:39.460569Z",
     "shell.execute_reply": "2022-04-02T04:10:39.459705Z",
     "shell.execute_reply.started": "2022-04-02T04:10:37.535322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded AutoEncoderVGGBlock3 from disk\n"
     ]
    }
   ],
   "source": [
    "# None of this is used now since we are using lightning\n",
    "# model = AutoEncoderVGGBlock3()\n",
    "\n",
    "# # Setup hyperparameters\n",
    "# # Configure lr and optimizer, may want to add weight decay\n",
    "# learning_rate = 1e-3\n",
    "# optim = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# # We calculate the reconstruciton loss using l2 Norm\n",
    "# recon_loss_func = torch.nn.MSELoss()\n",
    "# feature_loss_func = torch.nn.MSELoss()\n",
    "\n",
    "# # Number of epochs with batch size of 48 (may change this) on ~13k images per epoch\n",
    "# num_epochs = 10\n",
    "\n",
    "# train_vgg_block_3_ae = False\n",
    "# block_3_train_outputs = []\n",
    "# block_3_losses = []\n",
    "\n",
    "# if train_vgg_block_3_ae == True:\n",
    "#     # Move the model to GPU if exists for training\n",
    "#     model = model.to(device)\n",
    "    \n",
    "#     for epoch in range(num_epochs):\n",
    "#         for img, _ in tqdm(data_loader):\n",
    "#             # Move batch to GPU if available\n",
    "#             img = img.to(device)\n",
    "#             # Autoencode input batch\n",
    "#             recon = model(img)\n",
    "#             # Calculate reconstruction loss\n",
    "#             recon_loss = recon_loss_func(img, recon)\n",
    "#             # Calculate feature loss\n",
    "#             feature_loss = feature_loss_func(model.encode(img), model.encode(recon))\n",
    "#             # Calculate combined l2 norm\n",
    "#             total_loss = recon_loss + feature_loss\n",
    "#             # Reset optimizer gradients from previous batch\n",
    "#             optim.zero_grad()\n",
    "#             # Calculate gradient loss\n",
    "#             total_loss.backward()\n",
    "#             # Update parameters based on current gradient\n",
    "#             optim.step()\n",
    "\n",
    "#         # If the current epoch is the final epoch then we want to save the reconstructions and the input just so we can\n",
    "#         # check how things are learning\n",
    "#         # We should remove this later\n",
    "#         if epoch == num_epochs - 1: outputs.append((epoch, img.detach().cpu().numpy(), recon.detach().cpu().numpy()))\n",
    "#         block_3_train_outputs.append((epoch, img.detach().cpu().numpy(), recon.detach().cpu().numpy()))\n",
    "#         block_3_losses.append(loss.item())\n",
    "#         print(f'Epoch: {epoch + 1}, Loss:{loss.item():.4f}')\n",
    "#     # Move the model back to CPU to free up GPU memory\n",
    "#     model = model.cpu()\n",
    "    \n",
    "# else:\n",
    "#     model.load_state_dict(torch.load(\"models/vgg_ae_block_3.pth\"))\n",
    "#     block_3_losses = np.loadtxt(\"models/vgg_ae_block_3_losses.txt\").reshape(num_epochs, 1)\n",
    "#     print(\"Loaded AutoEncoderVGGBlock3 from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Choices for Style Transfer\n",
    "- [] Image Masking for multi style transfer\n",
    "- [] Blending multiple styled images\n",
    "- [] HSV Color Preserving Style Transfer\n",
    "\n",
    "### Things for Nick to Do:\n",
    "- [-] Lightning Module\n",
    "- [-] Embedding loss for block 1 (use the parameter: include_feature_loss) (I could not train this for long because \n",
    "I had to reduce batch size to fit on the GPU, so I do not know how well this works, try increasing the batch size and running on maneframe)\n",
    "- [-] Git repo\n",
    "- [-] Display evaluations\n",
    "- [-] Clean up model save/loading\n",
    "- [-] Save losses in the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1785a174ae2f4095b74f5a38132e1fe7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35614faf52264ac68a41ec725bb534df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6c57e6234ec14f6691da817cca81eef7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d7b2cbdd0cc34de7bd1f7527b1c392d0",
       "IPY_MODEL_83bca74c76474208835288131c388793",
       "IPY_MODEL_ac8b0740059c4ad3a75b8574bdd89622"
      ],
      "layout": "IPY_MODEL_f173347799e34260b215ee38d4d3f45b"
     }
    },
    "83bca74c76474208835288131c388793": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1785a174ae2f4095b74f5a38132e1fe7",
      "max": 2382,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_35614faf52264ac68a41ec725bb534df",
      "value": 223
     }
    },
    "ac8b0740059c4ad3a75b8574bdd89622": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8281def87974747bced6cfe3a2ceffd",
      "placeholder": "​",
      "style": "IPY_MODEL_cef1a49b35c94e088c6a18491313b473",
      "value": " 222/2382 [05:54&lt;53:28,  1.49s/it]"
     }
    },
    "c8219d2da72e417687aa9c7e986c6ecb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c8281def87974747bced6cfe3a2ceffd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cef1a49b35c94e088c6a18491313b473": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d7b2cbdd0cc34de7bd1f7527b1c392d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fd847bdd03034dc5b2557aea71b72a1f",
      "placeholder": "​",
      "style": "IPY_MODEL_c8219d2da72e417687aa9c7e986c6ecb",
      "value": "  9%"
     }
    },
    "f173347799e34260b215ee38d4d3f45b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fd847bdd03034dc5b2557aea71b72a1f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
