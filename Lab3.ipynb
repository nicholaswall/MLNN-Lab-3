{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T03:30:49.187594Z",
     "iopub.status.busy": "2022-04-02T03:30:49.187277Z",
     "iopub.status.idle": "2022-04-02T03:31:01.954470Z",
     "shell.execute_reply": "2022-04-02T03:31:01.953713Z",
     "shell.execute_reply.started": "2022-04-02T03:30:49.187519Z"
    },
    "id": "4oW6Xqe7NLUJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install --quiet torch torchvision matplotlib pytorch-lightning\n",
    "! pip install --quiet ipywidgets IProgress\n",
    "! jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T03:31:01.956348Z",
     "iopub.status.busy": "2022-04-02T03:31:01.956171Z",
     "iopub.status.idle": "2022-04-02T03:31:04.189062Z",
     "shell.execute_reply": "2022-04-02T03:31:04.188089Z",
     "shell.execute_reply.started": "2022-04-02T03:31:01.956322Z"
    },
    "id": "5Vx6AeRCNRfW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch 1.11.0a0+17540c5\n",
      "Is the GPU available? True\n",
      "Device cuda\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from IPython.display import set_matplotlib_formats\n",
    "from matplotlib.colors import to_rgba\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.nn.modules.conv import Conv2d, ConvTranspose2d\n",
    "from torch.nn.modules.activation import ReLU, Sigmoid\n",
    "import torchvision\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Using torch\", torch.__version__)\n",
    "torch.manual_seed(42)\n",
    "gpu_avail = torch.cuda.is_available()\n",
    "print(f\"Is the GPU available? {gpu_avail}\")\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T03:31:05.940302Z",
     "iopub.status.busy": "2022-04-02T03:31:05.939480Z",
     "iopub.status.idle": "2022-04-02T03:31:16.921372Z",
     "shell.execute_reply": "2022-04-02T03:31:16.920611Z",
     "shell.execute_reply.started": "2022-04-02T03:31:05.940273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "transform = transforms.Compose([\n",
    "      transforms.ToTensor(),                 \n",
    "])\n",
    "lfw_data = datasets.LFWPeople(root=\"./data\", split=\"train\", download=True, transform=transform)\n",
    "data_loader = DataLoader(dataset=lfw_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T23:37:01.271980Z",
     "iopub.status.busy": "2022-04-01T23:37:01.271258Z",
     "iopub.status.idle": "2022-04-01T23:37:03.158817Z",
     "shell.execute_reply": "2022-04-01T23:37:03.158079Z",
     "shell.execute_reply.started": "2022-04-01T23:37:01.271953Z"
    },
    "id": "OHhUCBAtRUZK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True)]\n"
     ]
    }
   ],
   "source": [
    "class AutoEncoderVGGBlock1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.LAMBDA = 1\n",
    "        vgg19 = torchvision.models.vgg19(pretrained=True)\n",
    "        vgg_layers = list(list(vgg19.children())[0].children())[:-33]\n",
    "        vgg = nn.Sequential(*vgg_layers)\n",
    "        for p in vgg.parameters():\n",
    "            p.requires_grad = False\n",
    "        print(vgg_layers)\n",
    "\n",
    "        self.encoder = vgg\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 64, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, 3, stride=1, padding=1),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def loss_func(self, original, reconstructed):\n",
    "        latent_original = self.encoder(original)\n",
    "        latent_reconstructed = self.encoder(reconstructed)\n",
    "        second = torch.sum(torch.square(latent_reconstructed - latent_original))\n",
    "        first = torch.sum(torch.square(reconstructed - original))\n",
    "        out = first + self.LAMBDA * second\n",
    "        return out\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "6c57e6234ec14f6691da817cca81eef7",
      "d7b2cbdd0cc34de7bd1f7527b1c392d0",
      "83bca74c76474208835288131c388793",
      "ac8b0740059c4ad3a75b8574bdd89622",
      "f173347799e34260b215ee38d4d3f45b",
      "fd847bdd03034dc5b2557aea71b72a1f",
      "c8219d2da72e417687aa9c7e986c6ecb",
      "1785a174ae2f4095b74f5a38132e1fe7",
      "35614faf52264ac68a41ec725bb534df",
      "c8281def87974747bced6cfe3a2ceffd",
      "cef1a49b35c94e088c6a18491313b473"
     ]
    },
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-04-01T23:37:04.310429Z",
     "iopub.status.busy": "2022-04-01T23:37:04.309708Z",
     "iopub.status.idle": "2022-04-01T23:56:05.576775Z",
     "shell.execute_reply": "2022-04-01T23:56:05.576112Z",
     "shell.execute_reply.started": "2022-04-01T23:37:04.310399Z"
    },
    "id": "Sim6d7SrR22P",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "779639f5-2bbe-40a1-dbd9-9e813ca23a59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "132e465539ed4f26b917bf92db4773d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:0.0026\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc80df298ba413bb5bfef391f4c1baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss:0.0016\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d01188c8bb084f41945a0b3b57da6f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss:0.0018\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7349cbe6b83740c1a92b5b57eb6da070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss:0.0012\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f489abf35c5c47c5ac000332ff15a4d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss:0.0015\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d3b807b53347efa16ba2e094aa14d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss:0.0012\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16c243213a548709cced2a853434698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss:0.0010\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7211b54673df45f9906b8c3eac9e14ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Loss:0.0010\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c2786e6c2e04ed8a76040de8aef2da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Loss:0.0016\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "449138585c684a22889fc82c955dd857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss:0.0009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoEncoderVGGBlock1(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): ConvTranspose2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoEncoderVGGBlock1()\n",
    "\n",
    "# Setup hyperparameters\n",
    "# Configure lr and optimizer, may want to add weight decay\n",
    "learning_rate = 1e-3\n",
    "optim = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# We calculate the reconstruciton loss using l2 Norm\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "# Number of epochs with batch size of 48 (may change this) on ~13k images per epoch\n",
    "num_epochs = 10\n",
    "\n",
    "train_vgg_block_1_ae = False\n",
    "block_1_train_outputs = []\n",
    "block_1_losses = []\n",
    "\n",
    "if train_vgg_block_1_ae == True:\n",
    "    # Move the model to GPU if exists for training\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for img, _ in tqdm(data_loader):\n",
    "            # Move batch to GPU if available\n",
    "            if device.type == \"cuda\": img = img.cuda()\n",
    "            # Autoencode input batch\n",
    "            recon = model(img)\n",
    "            # Calculate reconstruction loss\n",
    "            loss = loss_func(img, recon)\n",
    "            # Reset optimizer gradients from previous batch\n",
    "            optim.zero_grad()\n",
    "            # Calculate gradient loss\n",
    "            loss.backward()\n",
    "            # Update parameters based on current gradient\n",
    "            optim.step()\n",
    "\n",
    "        # If the current epoch is the final epoch then we want to save the reconstructions and the input just so we can\n",
    "        # check how things are learning\n",
    "        # We should remove this later\n",
    "        if epoch == num_epochs - 1: outputs.append((epoch, img.detach().cpu().numpy(), recon.detach().cpu().numpy()))\n",
    "        block_1_train_outputs.append((epoch, img.detach().cpu().numpy(), recon.detach().cpu().numpy()))\n",
    "        block_3_losses.append(loss.item())\n",
    "        print(f'Epoch: {epoch + 1}, Loss:{loss.item():.4f}')\n",
    "    # Move the model back to CPU to free up GPU memory\n",
    "    model.cpu()\n",
    "    \n",
    "else:\n",
    "    model.load_state_dict(torch.load(\"models/vgg_ae_block_1.pth\"))\n",
    "    block_1_losses = np.loadtxt(\"models/vgg_ae_block_1_losses.txt\").reshape(num_epochs, 1)\n",
    "    print(\"Loaded AutoEncoderVGGBlock1 from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T00:08:05.641319Z",
     "iopub.status.busy": "2022-04-02T00:08:05.641065Z",
     "iopub.status.idle": "2022-04-02T00:08:05.672311Z",
     "shell.execute_reply": "2022-04-02T00:08:05.671668Z",
     "shell.execute_reply.started": "2022-04-02T00:08:05.641295Z"
    }
   },
   "outputs": [],
   "source": [
    "save_vgg_block_1_ae = False\n",
    "if save_vgg_block_1_ae: \n",
    "    torch.save(model.state_dict(), 'models/vgg_ae_block_1.pth')\n",
    "    np.savetxt(\"models/vgg_ae_block_1.txt\", np.array(block_1_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T03:34:11.971900Z",
     "iopub.status.busy": "2022-04-02T03:34:11.971587Z",
     "iopub.status.idle": "2022-04-02T03:34:11.983161Z",
     "shell.execute_reply": "2022-04-02T03:34:11.982246Z",
     "shell.execute_reply.started": "2022-04-02T03:34:11.971861Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn.modules.conv import Conv2d, ConvTranspose2d\n",
    "from torch.nn.modules.activation import ReLU, Sigmoid\n",
    "import torchvision\n",
    "\n",
    "class AutoEncoderVGGBlock3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.LAMBDA = 1\n",
    "        vgg19 = torchvision.models.vgg19(pretrained=True)\n",
    "        vgg_layers = list(list(vgg19.children())[0].children())[:-19]\n",
    "        vgg = nn.Sequential(*vgg_layers)\n",
    "        for p in vgg.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        self.encoder = vgg\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 256, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 256, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 256, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 64, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, 3, stride=1, padding=0),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def loss_func(self, original, reconstructed):\n",
    "        latent_original = self.encoder(original)\n",
    "        latent_reconstructed = self.encoder(reconstructed)\n",
    "        second = torch.sum(torch.square(latent_reconstructed - latent_original))\n",
    "        first = torch.sum(torch.square(reconstructed - original))\n",
    "        out = first + self.LAMBDA * second\n",
    "        return out\n",
    "    \n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T04:10:37.535350Z",
     "iopub.status.busy": "2022-04-02T04:10:37.534746Z",
     "iopub.status.idle": "2022-04-02T04:10:39.460569Z",
     "shell.execute_reply": "2022-04-02T04:10:39.459705Z",
     "shell.execute_reply.started": "2022-04-02T04:10:37.535322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded AutoEncoderVGGBlock3 from disk\n"
     ]
    }
   ],
   "source": [
    "model = AutoEncoderVGGBlock3()\n",
    "\n",
    "# Setup hyperparameters\n",
    "# Configure lr and optimizer, may want to add weight decay\n",
    "learning_rate = 1e-3\n",
    "optim = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# We calculate the reconstruciton loss using l2 Norm\n",
    "recon_loss_func = torch.nn.MSELoss()\n",
    "feature_loss_func = torch.nn.MSELoss()\n",
    "\n",
    "# Number of epochs with batch size of 48 (may change this) on ~13k images per epoch\n",
    "num_epochs = 10\n",
    "\n",
    "train_vgg_block_3_ae = False\n",
    "block_3_train_outputs = []\n",
    "block_3_losses = []\n",
    "\n",
    "if train_vgg_block_3_ae == True:\n",
    "    # Move the model to GPU if exists for training\n",
    "    model = model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for img, _ in tqdm(data_loader):\n",
    "            # Move batch to GPU if available\n",
    "            img = img.to(device)\n",
    "            # Autoencode input batch\n",
    "            recon = model(img)\n",
    "            # Calculate reconstruction loss\n",
    "            recon_loss = recon_loss_func(img, recon)\n",
    "            # Calculate feature loss\n",
    "            feature_loss = feature_loss_func(model.encode(img), model.encode(recon))\n",
    "            # Calculate combined l2 norm\n",
    "            total_loss = recon_loss + feature_loss\n",
    "            # Reset optimizer gradients from previous batch\n",
    "            optim.zero_grad()\n",
    "            # Calculate gradient loss\n",
    "            total_loss.backward()\n",
    "            # Update parameters based on current gradient\n",
    "            optim.step()\n",
    "\n",
    "        # If the current epoch is the final epoch then we want to save the reconstructions and the input just so we can\n",
    "        # check how things are learning\n",
    "        # We should remove this later\n",
    "        if epoch == num_epochs - 1: outputs.append((epoch, img.detach().cpu().numpy(), recon.detach().cpu().numpy()))\n",
    "        block_3_train_outputs.append((epoch, img.detach().cpu().numpy(), recon.detach().cpu().numpy()))\n",
    "        block_3_losses.append(loss.item())\n",
    "        print(f'Epoch: {epoch + 1}, Loss:{loss.item():.4f}')\n",
    "    # Move the model back to CPU to free up GPU memory\n",
    "    model = model.cpu()\n",
    "    \n",
    "else:\n",
    "    model.load_state_dict(torch.load(\"models/vgg_ae_block_3.pth\"))\n",
    "    block_3_losses = np.loadtxt(\"models/vgg_ae_block_3_losses.txt\").reshape(num_epochs, 1)\n",
    "    print(\"Loaded AutoEncoderVGGBlock3 from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_vgg_block_3_ae = False\n",
    "if save_vgg_block_3_ae: \n",
    "    torch.save(model.state_dict(), 'models/vgg_ae_block_3.pth')\n",
    "    np.savetxt(\"models/vgg_ae_block_3.txt\", np.array(block_3_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Choices for Style Transfer\n",
    "- [] Image Masking for multi style transfer\n",
    "- [] Blending multiple styled images\n",
    "- [] HSV Color Preserving Style Transfer\n",
    "\n",
    "### Things for Nick to Do:\n",
    "- [] Lightning Module\n",
    "- [] Embedding loss for block 1 (did not do because I am not sure how that worked for the block 3 model, needs training to see how it worked out)\n",
    "- [] Git repo\n",
    "- [-] Display evaluations\n",
    "- [-] Clean up model save/loading\n",
    "- [-] Save losses in the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1785a174ae2f4095b74f5a38132e1fe7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35614faf52264ac68a41ec725bb534df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6c57e6234ec14f6691da817cca81eef7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d7b2cbdd0cc34de7bd1f7527b1c392d0",
       "IPY_MODEL_83bca74c76474208835288131c388793",
       "IPY_MODEL_ac8b0740059c4ad3a75b8574bdd89622"
      ],
      "layout": "IPY_MODEL_f173347799e34260b215ee38d4d3f45b"
     }
    },
    "83bca74c76474208835288131c388793": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1785a174ae2f4095b74f5a38132e1fe7",
      "max": 2382,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_35614faf52264ac68a41ec725bb534df",
      "value": 223
     }
    },
    "ac8b0740059c4ad3a75b8574bdd89622": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8281def87974747bced6cfe3a2ceffd",
      "placeholder": "​",
      "style": "IPY_MODEL_cef1a49b35c94e088c6a18491313b473",
      "value": " 222/2382 [05:54&lt;53:28,  1.49s/it]"
     }
    },
    "c8219d2da72e417687aa9c7e986c6ecb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c8281def87974747bced6cfe3a2ceffd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cef1a49b35c94e088c6a18491313b473": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d7b2cbdd0cc34de7bd1f7527b1c392d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fd847bdd03034dc5b2557aea71b72a1f",
      "placeholder": "​",
      "style": "IPY_MODEL_c8219d2da72e417687aa9c7e986c6ecb",
      "value": "  9%"
     }
    },
    "f173347799e34260b215ee38d4d3f45b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fd847bdd03034dc5b2557aea71b72a1f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
